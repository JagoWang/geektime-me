{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本改写和内容审核，别让你的机器人说错话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f8f55656588f130992441301ed4be11d in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[1;32m     18\u001b[0m long_text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39m在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39m在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m只有这样，我们才能真正地实现自己的潜力并取得成功。\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m short_version \u001b[39m=\u001b[39m make_text_short(long_text)\n\u001b[1;32m     28\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m short_version[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m, in \u001b[0;36mmake_text_short\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m messages\u001b[39m.\u001b[39mappend( {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m      6\u001b[0m messages\u001b[39m.\u001b[39mappend( {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: text})\n\u001b[0;32m----> 7\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      8\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m     10\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     n\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f8f55656588f130992441301ed4be11d in your message.)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def make_text_short(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=2048,\n",
    "        presence_penalty=0, # 对于已经生成token再次生成惩罚值，默认0\n",
    "        frequency_penalty=2, # 对于重复生成的token进行概率惩罚（-2～2）\n",
    "        n=3, # 返回3个答案\n",
    "    )\n",
    "    return response\n",
    "\n",
    "long_text = \"\"\"\n",
    "在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。\n",
    "在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\n",
    "还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。\n",
    "面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。\n",
    "这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。\n",
    "只有这样，我们才能真正地实现自己的潜力并取得成功。\n",
    "\"\"\"\n",
    "short_version = make_text_short(long_text)\n",
    "\n",
    "index = 1\n",
    "for choice in short_version[\"choices\"]:\n",
    "    print(f\"version {index}: \" + choice[\"message\"][\"content\"])\n",
    "    index += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过 logit_bias 参数精确控制内容\n",
    "#### 不过，无论是 temperature 还是 presence_penalty 和 frequency_penalty，都是一个参数，我们没有办法精确控制哪些词我们不想出现。不过，对于这一点，OpenAI 还是提供了解决方案，比如，我们想要在上面生成的内容里面，不允许出现灾害两个字，就可以这么做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[535]\n",
      "version 1: 现代社会中，我们面临各种挑战和困难，有外部的如经济、环境问题等，也有内部的情感、健康和自我怀疑等。要克服这些困难需要积极应对，并具备坚韧不拔的意志和创造性思维能力，并寻求外部支持。只有这样才能实现潜力并取得成功。\n",
      "version 2: 现代社会充满挑战和困难，有内在和外在的因素。我们需要积极应对，包括坚韧不拔、创造性思维和寻求支持等方法来实现潜力并取得成功。\n",
      "version 3: 现代社会中，我们面临各种挑战和困难，有些是外部因素引起的（如经济萧条、自然灾害），还有些是内部因素引起的（如情感问题、健康问题）。要克服这些困难，需要积极态度和行动，并具备坚韧意志、创造性思维以及寻求支持的能力。只有这样才能实现潜力并获得成功。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding('p50k_base')\n",
    "token_ids = encoding.encode(\"灾害\")\n",
    "print(token_ids)\n",
    "\n",
    "bias_map = {}\n",
    "for token_id in token_ids:\n",
    "    bias_map[token_id] = -100 # value range (-100~100), 一般情况下，设置在 1 到 -1 之间就足够了\n",
    "\n",
    "def make_text_short(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages, temperature=0.5, max_tokens=2048,\n",
    "        n=3, presence_penalty=0, frequency_penalty=2, \n",
    "        logit_bias = bias_map,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "short_version = make_text_short(long_text)\n",
    "\n",
    "index = 1\n",
    "for choice in short_version[\"choices\"]:\n",
    "    print(f\"version {index}: \" + choice[\"message\"][\"content\"])\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this fast-paced modern society, each of us faces various challenges and difficulties. Some of these challenges and difficulties are caused by external factors, such as economic recession, global warming, and natural disasters. Others are caused by internal factors, such as emotional issues, health problems, and self-doubt. To overcome these challenges and difficulties, we need to adopt a positive attitude and take action. This means that we must have a strong will and creative thinking, as well as the ability to seek external support. Only in this way can we truly realize our potential and achieve success.\n",
      "chinese: 432 tokens\n",
      "english: 117 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def translate(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"你是一个翻译，把用户的话翻译成英文\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages, temperature=0.5, max_tokens=2048,        n=1\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "chinese = long_text\n",
    "english = translate(chinese)\n",
    "\n",
    "num_of_tokens_in_chinese = len(encoding.encode(chinese))\n",
    "num_of_tokens_in_english = len(encoding.encode(english))\n",
    "print(english)\n",
    "print(f\"chinese: {num_of_tokens_in_chinese} tokens\")\n",
    "print(f\"english: {num_of_tokens_in_english} tokens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看openai提供哪些模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babbage</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>davinci</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text-davinci-edit-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>babbage-code-search-code</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-similarity-babbage-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>code-davinci-edit-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>babbage-code-search-text</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>babbage-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>code-search-babbage-text-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>text-curie-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>code-search-babbage-code-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text-embedding-ada-002</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>text-similarity-ada-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>curie-instruct-beta</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ada-code-search-code</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ada-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>code-search-ada-text-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>text-search-ada-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>davinci-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ada-code-search-text</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>text-search-ada-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>davinci-instruct-beta</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>text-similarity-curie-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>code-search-ada-code-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ada-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>text-search-davinci-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>curie-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>davinci-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>babbage-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ada-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>text-search-curie-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>whisper-1</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>text-search-babbage-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>curie-search-document</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>openai-internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>text-search-curie-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>babbage-search-query</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>text-search-davinci-doc-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>text-search-babbage-query-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>curie-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>curie</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>text-similarity-davinci-001</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>davinci-similarity</td>\n",
       "      <td>openai-dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id            owner\n",
       "0                         babbage           openai\n",
       "1                         davinci           openai\n",
       "2           text-davinci-edit-001           openai\n",
       "3        babbage-code-search-code       openai-dev\n",
       "4     text-similarity-babbage-001       openai-dev\n",
       "5           code-davinci-edit-001           openai\n",
       "6                text-davinci-001           openai\n",
       "7                             ada           openai\n",
       "8        babbage-code-search-text       openai-dev\n",
       "9              babbage-similarity       openai-dev\n",
       "10   code-search-babbage-text-001       openai-dev\n",
       "11                 text-curie-001           openai\n",
       "12   code-search-babbage-code-001       openai-dev\n",
       "13                   text-ada-001           openai\n",
       "14         text-embedding-ada-002  openai-internal\n",
       "15        text-similarity-ada-001       openai-dev\n",
       "16            curie-instruct-beta           openai\n",
       "17           ada-code-search-code       openai-dev\n",
       "18                 ada-similarity       openai-dev\n",
       "19       code-search-ada-text-001       openai-dev\n",
       "20      text-search-ada-query-001       openai-dev\n",
       "21        davinci-search-document       openai-dev\n",
       "22           ada-code-search-text       openai-dev\n",
       "23        text-search-ada-doc-001       openai-dev\n",
       "24          davinci-instruct-beta           openai\n",
       "25                  gpt-3.5-turbo           openai\n",
       "26      text-similarity-curie-001       openai-dev\n",
       "27       code-search-ada-code-001       openai-dev\n",
       "28               ada-search-query       openai-dev\n",
       "29  text-search-davinci-query-001       openai-dev\n",
       "30             curie-search-query       openai-dev\n",
       "31             gpt-3.5-turbo-0301           openai\n",
       "32           davinci-search-query       openai-dev\n",
       "33        babbage-search-document       openai-dev\n",
       "34            ada-search-document       openai-dev\n",
       "35    text-search-curie-query-001       openai-dev\n",
       "36                      whisper-1  openai-internal\n",
       "37    text-search-babbage-doc-001       openai-dev\n",
       "38          curie-search-document       openai-dev\n",
       "39               text-davinci-003  openai-internal\n",
       "40      text-search-curie-doc-001       openai-dev\n",
       "41           babbage-search-query       openai-dev\n",
       "42               text-babbage-001           openai\n",
       "43    text-search-davinci-doc-001       openai-dev\n",
       "44  text-search-babbage-query-001       openai-dev\n",
       "45               curie-similarity       openai-dev\n",
       "46                          curie           openai\n",
       "47    text-similarity-davinci-001       openai-dev\n",
       "48               text-davinci-002           openai\n",
       "49             davinci-similarity       openai-dev"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# list all open ai models\n",
    "engines = openai.Engine.list()\n",
    "pd = pd.DataFrame(openai.Engine.list()['data'])\n",
    "display(pd[['id', 'owner']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding-ada:  1536\n",
      "similarity-ada:  1024\n",
      "babbage-similarity:  2048\n",
      "search-babbage-query:  2048\n",
      "curie-similarity:  4096\n",
      "davinci-similarity:  12288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "text = \"让我们来算算Embedding\"\n",
    "\n",
    "embedding_ada = get_embedding(text, engine=\"text-embedding-ada-002\")\n",
    "print(\"embedding-ada: \", len(embedding_ada))\n",
    "\n",
    "similarity_ada = get_embedding(text, engine=\"text-similarity-ada-001\")\n",
    "print(\"similarity-ada: \", len(similarity_ada))\n",
    "\n",
    "babbage_similarity = get_embedding(text, engine=\"babbage-similarity\")\n",
    "print(\"babbage-similarity: \", len(babbage_similarity))\n",
    "\n",
    "babbage_search_query = get_embedding(text, engine=\"text-search-babbage-query-001\")\n",
    "print(\"search-babbage-query: \", len(babbage_search_query))\n",
    "\n",
    "curie = get_embedding(text, engine=\"curie-similarity\")\n",
    "print(\"curie-similarity: \", len(curie))\n",
    "\n",
    "davinci = get_embedding(text, engine=\"text-similarity-davinci-001\")\n",
    "print(\"davinci-similarity: \", len(davinci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "另外一些则是由我们个人造成的，例如被阻碍实现梦想或想法创新的能力。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prefix = \"\"\"在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。\n",
    "在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\\n\"\"\"\n",
    "# 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。\n",
    "suffix = \"\"\"\\n面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。\n",
    "这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。\n",
    "只有这样，我们才能真正地实现自己的潜力并取得成功。\"\"\"\n",
    "\n",
    "def insert_text(prefix, suffix):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prefix,\n",
    "        suffix=suffix,\n",
    "        max_tokens=1024,\n",
    "        )\n",
    "    return response\n",
    "\n",
    "response = insert_text(prefix, suffix)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此外，有些则是由于内在因素如健康问题、失业和低收入导致的。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prefix = \"\"\"在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。\n",
    "在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\\n\"\"\"\n",
    "# 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。\n",
    "suffix = \"\"\"面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。\n",
    "这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。\n",
    "只有这样，我们才能真正地实现自己的潜力并取得成功。\"\"\"\n",
    "\n",
    "response = insert_text(prefix, suffix)\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不要乱问乱说，做个“正直”的 AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个语言模型程序，没有实体，也不会感受到疼痛。我只能根据您输入的内容提供相应的回复。请不要使用恶意或暴力的言语，让我们保持友好和平的交流。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chatgpt(text):\n",
    "    messages = []\n",
    "    messages.append( {\"role\": \"system\", \"content\": \"You are a useful AI assistant\"})\n",
    "    messages.append( {\"role\": \"user\", \"content\": text})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0.5,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "    )\n",
    "    message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return message\n",
    "\n",
    "threaten = \"你不听我的我就拿刀砍死你\"\n",
    "print(chatgpt(threaten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"categories\": {\n",
      "    \"hate\": false,\n",
      "    \"hate/threatening\": false,\n",
      "    \"self-harm\": false,\n",
      "    \"sexual\": false,\n",
      "    \"sexual/minors\": false,\n",
      "    \"violence\": true,\n",
      "    \"violence/graphic\": false\n",
      "  },\n",
      "  \"category_scores\": {\n",
      "    \"hate\": 0.030033884570002556,\n",
      "    \"hate/threatening\": 0.0002820953668560833,\n",
      "    \"self-harm\": 0.004850297700613737,\n",
      "    \"sexual\": 2.2907945094630122e-05,\n",
      "    \"sexual/minors\": 6.4779466235620475e-09,\n",
      "    \"violence\": 0.9996402263641357,\n",
      "    \"violence/graphic\": 4.355868077254854e-05\n",
      "  },\n",
      "  \"flagged\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threaten = \"你不听我的我就拿刀砍死你\"\n",
    "\n",
    "def moderation(text):\n",
    "    response = openai.Moderation.create(\n",
    "        input=text\n",
    "    )\n",
    "    output = response[\"results\"][0]\n",
    "    return output\n",
    "print(moderation(threaten))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
