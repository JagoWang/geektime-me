{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本聚类与摘要，让AI帮你做个总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "\n",
    "def twenty_newsgroup_to_csv():\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "    df = pd.DataFrame([newsgroups_train.data, newsgroups_train.target.tolist()]).T\n",
    "    df.columns = ['text', 'target']\n",
    "\n",
    "    targets = pd.DataFrame( newsgroups_train.target_names, columns=['title'])\n",
    "\n",
    "    out = pd.merge(df, targets, left_on='target', right_index=True)\n",
    "    out.to_csv('20_newsgroup.csv', index=False)\n",
    "    \n",
    "twenty_newsgroup_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before null filtering: 11314\n",
      "Number of rows before token number filtering: 11096\n",
      "Number of rows data used: 11044\n"
     ]
    }
   ],
   "source": [
    "from openai.embeddings_utils import get_embeddings\n",
    "import openai, os, tiktoken, backoff\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "batch_size = 2000\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "\n",
    "df = pd.read_csv('20_newsgroup.csv')\n",
    "print(\"Number of rows before null filtering:\", len(df))\n",
    "df = df[df['text'].isnull() == False]\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "df[\"n_tokens\"] = df.text.apply(lambda x: len(encoding.encode(x)))\n",
    "print(\"Number of rows before token number filtering:\", len(df))\n",
    "df = df[df.n_tokens <= max_tokens]\n",
    "print(\"Number of rows data used:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def get_embeddings_with_backoff(prompts, engine):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        embeddings += get_embeddings(list_of_text=batch, engine=engine)\n",
    "    return embeddings\n",
    "\n",
    "prompts = df.text.tolist()\n",
    "prompt_batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]\n",
    "\n",
    "embeddings = []\n",
    "for batch in prompt_batches:\n",
    "    batch_embeddings = get_embeddings_with_backoff(prompts=batch, engine=embedding_model)\n",
    "    embeddings += batch_embeddings\n",
    "\n",
    "df[\"embedding\"] = embeddings\n",
    "df.to_parquet(\"data/20_newsgroup_with_embedding.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedding_df = pd.read_parquet(\"data/20_newsgroup_with_embedding.parquet\")\n",
    "\n",
    "matrix = np.vstack(embedding_df.embedding.values)\n",
    "num_of_clusters = 20\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_of_clusters, init=\"k-means++\", n_init=10, random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_\n",
    "embedding_df[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1z/93qs6_x179d3cn0f0_d8n0pr0000gn/T/ipykernel_20404/1662701326.py:13: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  second_titles = second_titles.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>count</th>\n",
       "      <th>rank1</th>\n",
       "      <th>rank1_count</th>\n",
       "      <th>rank2</th>\n",
       "      <th>rank2_count</th>\n",
       "      <th>first_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>556</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>387</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>477</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1164</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>152</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>8</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>463</td>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>419</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>480</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>218</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>69.0</td>\n",
       "      <td>45.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>891</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>367</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>387</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>372</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>512</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>506</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>432</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>10.0</td>\n",
       "      <td>85.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>531</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>684</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>242</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>149</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>45.0</td>\n",
       "      <td>61.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>505</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>492</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.43%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>664</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>418</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>161.0</td>\n",
       "      <td>62.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>472</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>467</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>854</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>718</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>284</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  count                     rank1  rank1_count               rank2  \\\n",
       "0         0    556              misc.forsale          452                   0   \n",
       "1         1    387           rec.motorcycles          369                   0   \n",
       "2         2    477                 sci.space          432                   0   \n",
       "3         3   1164        talk.politics.misc          152  talk.religion.misc   \n",
       "4         4     84   comp.os.ms-windows.misc            8  talk.religion.misc   \n",
       "5         5    463            comp.windows.x          419                   0   \n",
       "6         6    480               alt.atheism          218  talk.religion.misc   \n",
       "7         7    891             comp.graphics          367  talk.religion.misc   \n",
       "8         8    387                 sci.crypt          372                   0   \n",
       "9         9    512        rec.sport.baseball          494                   0   \n",
       "10       10    506     talk.politics.mideast          432  talk.religion.misc   \n",
       "11       11    531                 rec.autos          439                   0   \n",
       "12       12    684     comp.sys.mac.hardware          215                   0   \n",
       "13       13    242        talk.politics.guns          149  talk.religion.misc   \n",
       "14       14    505          rec.sport.hockey          492                   0   \n",
       "15       15    664    soc.religion.christian          418  talk.religion.misc   \n",
       "16       16    472                   sci.med          438                   0   \n",
       "17       17    467           sci.electronics          336                   0   \n",
       "18       18    854  comp.sys.ibm.pc.hardware          311                   0   \n",
       "19       19    718        talk.politics.guns          284  talk.religion.misc   \n",
       "\n",
       "    rank2_count first_percentage  \n",
       "0           0.0           81.29%  \n",
       "1           0.0           95.35%  \n",
       "2           0.0           90.57%  \n",
       "3          66.0           13.06%  \n",
       "4           2.0            9.52%  \n",
       "5           0.0           90.50%  \n",
       "6          69.0           45.42%  \n",
       "7           1.0           41.19%  \n",
       "8           0.0           96.12%  \n",
       "9           0.0           96.48%  \n",
       "10         10.0           85.38%  \n",
       "11          0.0           82.67%  \n",
       "12          0.0           31.43%  \n",
       "13         45.0           61.57%  \n",
       "14          0.0           97.43%  \n",
       "15        161.0           62.95%  \n",
       "16          0.0           92.80%  \n",
       "17          0.0           71.95%  \n",
       "18          0.0           36.42%  \n",
       "19          9.0           39.55%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 统计每个cluster的数量\n",
    "new_df = embedding_df.groupby('cluster')['cluster'].count().reset_index(name='count')\n",
    "\n",
    "# 统计这个cluster里最多的分类的数量\n",
    "title_count = embedding_df.groupby(['cluster', 'title']).size().reset_index(name='title_count')\n",
    "first_titles = title_count.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n",
    "first_titles = first_titles.reset_index(drop=True)\n",
    "new_df = pd.merge(new_df, first_titles[['cluster', 'title', 'title_count']], on='cluster', how='left')\n",
    "new_df = new_df.rename(columns={'title': 'rank1', 'title_count': 'rank1_count'})\n",
    "\n",
    "# 统计这个cluster里第二多的分类的数量\n",
    "second_titles = title_count[~title_count['title'].isin(first_titles['title'])]\n",
    "second_titles = second_titles.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n",
    "second_titles = second_titles.reset_index(drop=True)\n",
    "new_df = pd.merge(new_df, second_titles[['cluster', 'title', 'title_count']], on='cluster', how='left')\n",
    "new_df = new_df.rename(columns={'title': 'rank2', 'title_count': 'rank2_count'})\n",
    "new_df['first_percentage'] = (new_df['rank1_count'] / new_df['count']).map(lambda x: '{:.2%}'.format(x))\n",
    "# 将缺失值替换为 0\n",
    "new_df.fillna(0, inplace=True)\n",
    "# 输出结果\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Rank 1: misc.forsale, Theme: 电脑软件和硬件\n",
      "Cluster 1, Rank 1: rec.motorcycles, Theme: 骑行安全\n",
      "Cluster 2, Rank 1: sci.space, Theme: 航天技术研究\n",
      "Cluster 3, Rank 1: talk.politics.misc, Theme: 政治争议\n",
      "Cluster 4, Rank 1: comp.os.ms-windows.misc, Theme: 科技产品\"\"\"\n",
      "Cluster 5, Rank 1: comp.windows.x, Theme: PC硬件和窗口管理\n",
      "Cluster 6, Rank 1: alt.atheism, Theme: 宗教信仰与经验\n",
      "Cluster 7, Rank 1: comp.graphics, Theme: 软件分享\n",
      "Cluster 8, Rank 1: sci.crypt, Theme: 数字加密安全\n",
      "Cluster 9, Rank 1: rec.sport.baseball, Theme: 棒球讨论\n",
      "Cluster 10, Rank 1: talk.politics.mideast, Theme: "
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 5318 tokens (5218 in your prompt; 100 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCluster \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, Rank 1: \u001b[39m\u001b[39m{\u001b[39;00mcluster_name\u001b[39m}\u001b[39;00m\u001b[39m, Theme:\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m      9\u001b[0m     embedding_df[embedding_df\u001b[39m.\u001b[39mcluster \u001b[39m==\u001b[39m i]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msample(items_per_cluster, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     12\u001b[0m     model\u001b[39m=\u001b[39;49mCOMPLETIONS_MODEL,\n\u001b[1;32m     13\u001b[0m     prompt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'''\u001b[39;49m\u001b[39m我们想要给下面的内容，分组成有意义的类别，以便我们可以对其进行总结。请根据下面这些内容的共同点，总结一个50个字以内的新闻组的名称。比如 “PC硬件”\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m内容:\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mcontent\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m新闻组名称：\u001b[39;49m\u001b[39m'''\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 5318 tokens (5218 in your prompt; 100 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "\n",
    "items_per_cluster = 10\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "\n",
    "for i in range(num_of_clusters):\n",
    "    cluster_name = new_df[new_df.cluster == i].iloc[0].rank1\n",
    "    print(f\"Cluster {i}, Rank 1: {cluster_name}, Theme:\", end=\" \")\n",
    "\n",
    "    content = \"\\n\".join(\n",
    "        embedding_df[embedding_df.cluster == i].text.sample(items_per_cluster, random_state=42).values\n",
    "    )\n",
    "    response = openai.Completion.create(\n",
    "        model=COMPLETIONS_MODEL,\n",
    "        prompt=f'''我们想要给下面的内容，分组成有意义的类别，以便我们可以对其进行总结。请根据下面这些内容的共同点，总结一个50个字以内的新闻组的名称。比如 “PC硬件”\\n\\n内容:\\n\"\"\"\\n{content}\\n\"\"\"新闻组名称：''',\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        top_p=1,\n",
    "    )\n",
    "    print(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Rank 1: misc.forsale, 抽样翻译: 出售房屋！！！！新泽西州梅尔斯维尔16号布罗克顿路描述：美丽的3间卧室，1 1/2浴室的斗篷码头位于一个大型雅致的景观拐角处，有围栏。这个家有一个吃饭的厨房，有内置的角落瓷器橱柜，一个大客厅，地毯，硬木地板，新的瓷砖门厅，和新刷的中性色调装饰。这个家包括新的中央空调和暖气，新屋顶，新热水器，铝外墙，风暴窗户和门，以及Rockwell外墙隔热。还有一个新的部分完成的地下室，有外部入口和新的Duro棚屋。很多存储空间。靠近295号公路。额外：洗碗机，洗衣机和烘干机，吊扇，窗帘。请拨打（609）586-1946预约。\n",
      "Cluster 1, Rank 1: rec.motorcycles, 抽样翻译: 下次让数字更加可信——这是一个很糟糕的煽动性言论。120分贝接近于从几码远的地方听到的巨型喷气式飞机发动机起飞时的声音。它肯定接近人类的痛苦阈值。如果他们有任何标准，那么没有办法允许110分贝。\n",
      "Cluster 2, Rank 1: sci.space, 抽样翻译: 天文学符号（这是最后一个发布到sci.astro的FAQ部分）从sci.astro的各种符号发布中收集。光谱分类序列：O B A F G K M R N S噢，要成为一个美丽的女孩，现在就亲亲我，甜心。（经典）奥德尔的大天文学悲剧，现在肯定会杀死我肥胖的秃头天文学被判有罪，杀死了许多不情愿的非科学学生。octopus大脑，一个受欢迎的烹饪厨房菜单，不需要酱汁奇怪的天文学家发现一般都是怪诞的符号，真是太棒了噢，大而凶猛的大猩猩，下个星期杀死我的室友噢，天哪，一个F级杀死我在糟糕的下午，发酵的葡萄让理查德·尼克松太太微笑噢，向后的天文学家，忘记地心说；开普勒的运动揭示了自然的简单我们糟糕的天文学教授星期一被杀烤蚂蚁，慢慢煎，保湿，保持天然的鲜味海外广播：一个闪光！哥斯拉杀死莫斯拉！（罗丹被任命为继任者）超重的男孩和胖女孩一直在嚼只有无聊的天文学家才能找到知道符号的满足感噢，血腥的天文学！F级杀死我行星的顺序：太阳水星金星地球（泰拉）火星（小行星）木星土星天王星海王星冥王星我非常认真的母亲刚刚给我们九个披萨母亲非常体贴地做了一个果冻三明治，没有抗议我非常性感的伴侣兴致勃勃地满足了不寻常的需求男人很容易做壶服务有用的夜间用途男人很早就做了一个壶服务有用的高尚目的我非常有教养的母亲刚刚给我们展示了九个行星我非常热心的母亲刚刚给我们展示了九个行星我非常疲惫的母亲刚刚扫走了一个行星状星云大多数选民只要出现在投票站附近就可以赚到钱我非常有教养的母亲刚刚给我们九个披萨许多恶毒的大象让约翰，苏西和叔叔需要保护太阳质量很容易使木星的卫星都经历众多的扰动。我的父亲每个星期日向我解释我们九个可爱的行星永远不要轻视一个人的不幸 - 句号！光谱的颜色：红橙黄绿蓝靛紫ROY G. BIV（发音为男性名字）约克的理查德参加了徒劳的战斗念出你的好书来木星的伽利略卫星：伊奥普拉加尼米德卡利斯托我期望上帝哭泣我吃绿色奶酪我使好基督徒尴尬Ich erschrecke all guten Christen（我吓坏了所有的好基督徒）土星卫星MET DR THIP米丽姆的辣椒味道神圣。告诉她我很自豪。（米玛斯，恩塞拉度斯，泰提斯，迪奥尼，雷亚，泰坦，海皮昂，伊阿比特斯，菲比）天王星卫星：MAUTO对天王星的发音常常有误我的天使乌列尔服用鸦片（米兰达，爱丽丝，昂布\n",
      "Cluster 3, Rank 1: talk.politics.misc, 抽样翻译: 放弃你的武器。很快，官员们就会来收集它们。抵抗是没有用的。别告诉我——你是“博格·沃纳”，对吗？哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈\n",
      "Cluster 4, Rank 1: comp.os.ms-windows.misc, 抽样翻译: "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m cluster_name \u001b[39m=\u001b[39m new_df[new_df\u001b[39m.\u001b[39mcluster \u001b[39m==\u001b[39m i]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mrank1\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCluster \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m, Rank 1: \u001b[39m\u001b[39m{\u001b[39;00mcluster_name\u001b[39m}\u001b[39;00m\u001b[39m, 抽样翻译:\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m----> 9\u001b[0m     embedding_df[(embedding_df\u001b[39m.\u001b[39;49mcluster \u001b[39m==\u001b[39;49m i) \u001b[39m&\u001b[39;49m (embedding_df\u001b[39m.\u001b[39;49mn_tokens \u001b[39m>\u001b[39;49m \u001b[39m100\u001b[39;49m)]\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49msample(items_per_cluster, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     12\u001b[0m     model\u001b[39m=\u001b[39mCOMPLETIONS_MODEL,\n\u001b[1;32m     13\u001b[0m     prompt\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'''\u001b[39m\u001b[39m请把下面的内容翻译成中文\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m内容:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mcontent\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m翻译：\u001b[39m\u001b[39m'''\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     top_p\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/generic.py:5773\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5770\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5771\u001b[0m     weights \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mpreprocess_weights(\u001b[39mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 5773\u001b[0m sampled_indices \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39;49msample(obj_len, size, replace, weights, rs)\n\u001b[1;32m   5774\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(sampled_indices, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   5776\u001b[0m \u001b[39mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/pandas/core/sample.py:150\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid weights: weights sum to zero\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 150\u001b[0m \u001b[39mreturn\u001b[39;00m random_state\u001b[39m.\u001b[39;49mchoice(obj_len, size\u001b[39m=\u001b[39;49msize, replace\u001b[39m=\u001b[39;49mreplace, p\u001b[39m=\u001b[39;49mweights)\u001b[39m.\u001b[39mastype(\n\u001b[1;32m    151\u001b[0m     np\u001b[39m.\u001b[39mintp, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    152\u001b[0m )\n",
      "File \u001b[0;32mmtrand.pyx:928\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "\n",
    "items_per_cluster = 1\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "\n",
    "for i in range(num_of_clusters):\n",
    "    cluster_name = new_df[new_df.cluster == i].iloc[0].rank1\n",
    "    print(f\"Cluster {i}, Rank 1: {cluster_name}, 抽样翻译:\", end=\" \")\n",
    "\n",
    "    content = \"\\n\".join(\n",
    "        embedding_df[(embedding_df.cluster == i) & (embedding_df.n_tokens > 100)].text.sample(items_per_cluster, random_state=42).values\n",
    "    )\n",
    "    response = openai.Completion.create(\n",
    "        model=COMPLETIONS_MODEL,\n",
    "        prompt=f'''请把下面的内容翻译成中文\\n\\n内容:\\n\"\"\"\\n{content}\\n\"\"\"翻译：''',\n",
    "        temperature=0,\n",
    "        max_tokens=2000,\n",
    "        top_p=1,\n",
    "    )\n",
    "    print(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
